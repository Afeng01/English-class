"""
å°†æœ¬åœ°å­˜å‚¨çš„ä¹¦ç±å°é¢è¿ç§»åˆ°é˜¿é‡Œäº‘OSS
"""
import argparse
import logging
import os
import re
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
backend_dir = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(backend_dir))

from app.models.database import SessionLocal, Book, Chapter
from app.utils.oss_helper import oss_helper
from app.utils.supabase_client import supabase_client

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åŒ¹é…ç« èŠ‚å†…å®¹ä¸­å¼•ç”¨æœ¬åœ°é™æ€å›¾ç‰‡çš„ <img> æ ‡ç­¾
IMAGE_TAG_PATTERN = re.compile(r'<img[^>]+src=["\'](/static/images/[^"\']+)["\']', re.IGNORECASE)


def migrate_book_images(db, dry_run: bool = False):
    """è¿ç§»æœ¬åœ°å›¾ç‰‡åˆ°OSS"""
    if not oss_helper.enabled or oss_helper.backend != "ali_oss":
        logger.error("âŒ é˜¿é‡Œäº‘OSSæœªå¯ç”¨ï¼Œæ— æ³•æ‰§è¡Œè¿ç§»")
        logger.error("   è¯·ç¡®è®¤ .env ä¸­ USE_OSS=true ä¸”å·²æ­£ç¡®å®‰è£… / é…ç½® oss2")
        return

    books = db.query(Book).filter(Book.cover.like('/static/images/%')).all()
    if not books:
        logger.info("âœ… æ²¡æœ‰éœ€è¦è¿ç§»çš„ä¹¦ç±")
        return

    logger.info(f"ğŸ“¦ æ‰¾åˆ° {len(books)} æœ¬å°é¢ä»åœ¨æœ¬åœ°çš„ä¹¦ç±")
    success_count = 0
    fail_count = 0

    for book in books:
        logger.info("\n" + "-" * 40)
        logger.info(f"ğŸ“– å¤„ç†ä¹¦ç±: {book.title} ({book.id})")
        logger.info(f"æ—§å°é¢: {book.cover}")

        relative_path = book.cover.replace('/static/images/', '')
        local_path = backend_dir / 'data' / 'images' / relative_path

        if not local_path.exists():
            logger.warning(f"âš ï¸ æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {local_path}")
            fail_count += 1
            continue

        object_name = relative_path.replace('\\', '/')
        try:
            if dry_run:
                logger.info(f"[DRY RUN] å°†ä¸Šä¼ åˆ° OSS: {object_name}")
                success_count += 1
                continue

            with open(local_path, 'rb') as f:
                image_data = f.read()

            oss_url = oss_helper.upload_image(image_data, object_name)
            logger.info(f"âœ… ä¸Šä¼ æˆåŠŸ: {oss_url}")

            book.cover = oss_url
            db.commit()
            logger.info("âœ… æ•°æ®åº“å·²æ›´æ–°")

            if supabase_client.enabled:
                try:
                    supabase_client.client.table('books')\
                        .update({'cover': oss_url})\
                        .eq('id', book.id)\
                        .execute()
                    logger.info("âœ… Supabaseå·²åŒæ­¥")
                except Exception as e:
                    logger.warning(f"âš ï¸ SupabaseåŒæ­¥å¤±è´¥: {e}")

            success_count += 1
        except Exception as e:
            logger.error(f"âŒ è¿ç§»å¤±è´¥: {e}")
            db.rollback()
            fail_count += 1

    logger.info("\n" + "=" * 50)
    logger.info("ğŸ“Š è¿ç§»å®Œæˆ")
    logger.info(f"æˆåŠŸ: {success_count} æœ¬")
    logger.info(f"å¤±è´¥: {fail_count} æœ¬")
    logger.info("=" * 50)


def migrate_chapter_images(db, dry_run: bool = False):
    """è¿ç§»ç« èŠ‚å†…å®¹ä¸­çš„æœ¬åœ°å›¾ç‰‡å¼•ç”¨"""
    if not oss_helper.enabled or oss_helper.backend != "ali_oss":
        logger.error("âŒ é˜¿é‡Œäº‘OSSæœªå¯ç”¨ï¼Œæ— æ³•æ‰§è¡Œç« èŠ‚å†…å®¹è¿ç§»")
        return

    chapters = db.query(Chapter).filter(Chapter.content.contains('/static/images/')).all()
    if not chapters:
        logger.info("âœ… æ²¡æœ‰ç« èŠ‚å¼•ç”¨æœ¬åœ°å›¾ç‰‡ï¼Œæ— éœ€è¿ç§»")
        return

    logger.info(f"ğŸ“˜ æ‰¾åˆ° {len(chapters)} ä¸ªç« èŠ‚åŒ…å«æœ¬åœ°å›¾ç‰‡ï¼Œå‡†å¤‡è¿ç§»å†…å®¹ä¸­çš„å¼•ç”¨")
    total_images = 0
    uploaded_images = 0
    success_chapters = 0
    failed_chapters = 0
    dry_run_chapters = 0

    for chapter in chapters:
        try:
            content = chapter.content or ""
            image_paths = IMAGE_TAG_PATTERN.findall(content)
            unique_images = list(dict.fromkeys(image_paths))

            if not unique_images:
                logger.info(f"â„¹ï¸ ç« èŠ‚ {chapter.id} æ— æ³•è§£æå‡ºå›¾ç‰‡æ ‡ç­¾ï¼Œè·³è¿‡")
                continue

            total_images += len(unique_images)
            chapter_name = chapter.title or f"ç¬¬{chapter.chapter_number}ç« "
            book_title = chapter.book.title if chapter.book else "æœªçŸ¥ä¹¦ç±"

            logger.info("\n" + "-" * 40)
            logger.info(f"ğŸ“„ ç« èŠ‚: {chapter_name} ({chapter.id})")
            logger.info(f"ğŸ“š æ‰€å±ä¹¦ç±: {book_title} ({chapter.book_id})")
            logger.info(f"ğŸ–¼ï¸ æ‰¾åˆ° {len(unique_images)} å¼ æœ¬åœ°å›¾ç‰‡")

            replacements = []
            for image_path in unique_images:
                try:
                    relative_path = image_path.split('/static/images/', 1)[1]
                except IndexError:
                    logger.warning(f"âš ï¸ å›¾ç‰‡è·¯å¾„æ ¼å¼å¼‚å¸¸ï¼Œè·³è¿‡: {image_path}")
                    continue

                local_path = backend_dir / 'data' / 'images' / relative_path
                if not local_path.exists():
                    logger.warning(f"âš ï¸ æœ¬åœ°å›¾ç‰‡ä¸å­˜åœ¨: {local_path}")
                    continue

                object_name = relative_path.replace('\\', '/')
                if dry_run:
                    logger.info(f"[DRY RUN] å°†ä¸Šä¼ ç« èŠ‚å›¾ç‰‡: {image_path} -> {object_name}")
                    continue

                with open(local_path, 'rb') as f:
                    image_data = f.read()

                oss_url = oss_helper.upload_image(image_data, object_name)
                logger.info(f"âœ… ä¸Šä¼ ç« èŠ‚å›¾ç‰‡æˆåŠŸ: {oss_url}")
                replacements.append((image_path, oss_url))

            if dry_run:
                dry_run_chapters += 1
                continue

            if not replacements:
                logger.info("â„¹ï¸ æœªæ‰¾åˆ°å¯ä¸Šä¼ çš„å›¾ç‰‡ï¼Œè·³è¿‡æ•°æ®åº“æ›´æ–°")
                continue

            updated_content = content
            for src, dest in replacements:
                updated_content = updated_content.replace(src, dest)

            chapter.content = updated_content
            db.commit()
            success_chapters += 1
            uploaded_images += len(replacements)
            logger.info("âœ… ç« èŠ‚å†…å®¹å·²å†™å›æ•°æ®åº“")

            if supabase_client.enabled:
                try:
                    supabase_client.client.table('chapters')\
                        .update({'content': updated_content})\
                        .eq('id', chapter.id)\
                        .execute()
                    logger.info("âœ… Supabaseç« èŠ‚å†…å®¹å·²åŒæ­¥")
                except Exception as e:
                    logger.warning(f"âš ï¸ Supabaseç« èŠ‚åŒæ­¥å¤±è´¥: {e}")
        except Exception as e:
            logger.error(f"âŒ ç« èŠ‚ {chapter.id} è¿ç§»å¤±è´¥: {e}")
            db.rollback()
            failed_chapters += 1

    logger.info("\n" + "=" * 50)
    logger.info("ğŸ“Š ç« èŠ‚å†…å®¹è¿ç§»å®Œæˆ")
    logger.info(f"ç« èŠ‚æˆåŠŸ: {success_chapters}")
    logger.info(f"ç« èŠ‚å¤±è´¥: {failed_chapters}")
    logger.info(f"æ€»å…±è§£æå›¾ç‰‡: {total_images}")
    if dry_run:
        logger.info(f"Dry Run ç« èŠ‚: {dry_run_chapters}")
        logger.info("å®é™…ä¸Šä¼ å›¾ç‰‡: 0ï¼ˆé¢„è§ˆæ¨¡å¼ï¼‰")
    else:
        logger.info(f"å®é™…ä¸Šä¼ å›¾ç‰‡: {uploaded_images}")
    logger.info("=" * 50)


def main():
    parser = argparse.ArgumentParser(description="è¿ç§»æœ¬åœ°å›¾ç‰‡åˆ°é˜¿é‡Œäº‘OSS")
    parser.add_argument('--dry-run', action='store_true', help='é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…ä¸Šä¼ ')
    args = parser.parse_args()

    if args.dry_run:
        logger.info("ğŸ” é¢„è§ˆæ¨¡å¼ï¼ˆä¸ä¼šå®é™…ä¸Šä¼ ï¼‰")

    db = SessionLocal()
    try:
        migrate_book_images(db, dry_run=args.dry_run)
        migrate_chapter_images(db, dry_run=args.dry_run)
    finally:
        db.close()


if __name__ == "__main__":
    main()
