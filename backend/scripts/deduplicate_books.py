"""
ä¹¦ç±å»é‡è„šæœ¬
ä½¿ç”¨ç¤ºä¾‹ï¼š
    python deduplicate_books.py --dry-run   # ä»…æŸ¥çœ‹å°†è¢«åˆ é™¤çš„ä¹¦ç±
    python deduplicate_books.py             # å®é™…åˆ é™¤é‡å¤ä¹¦ç±
"""
import argparse
import logging
import os
import sys
from collections import defaultdict
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Tuple

# å°† backend ç›®å½•åŠ å…¥æ¨¡å—æœç´¢è·¯å¾„ï¼Œä¾¿äºå¯¼å…¥ app åŒ…
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from sqlalchemy.orm import Session  # noqa: E402

from app.models.database import Book, BookVocabulary, Chapter, SessionLocal  # noqa: E402
from app.utils.oss_helper import oss_helper  # noqa: E402
from app.utils.supabase_client import supabase_client  # noqa: E402

# æ—¶åŒºï¼šä¸­å›½æ ‡å‡†æ—¶é—´
CN_TZ = timezone(timedelta(hours=8))

# ç›®å½•è·¯å¾„
BACKEND_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
PROJECT_ROOT = os.path.dirname(BACKEND_DIR)
CLAUDE_DIR = os.path.join(PROJECT_ROOT, ".claude")

# æ—¥å¿—é…ç½®
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logger = logging.getLogger(__name__)


def normalize_title(title: str) -> str:
    """å½’ä¸€åŒ–æ ‡é¢˜ï¼Œç”¨äºåˆ¤å®šé‡å¤ã€‚"""
    if not title:
        return ""
    return title.strip().lower()


def has_cover(book: Book) -> bool:
    """åˆ¤æ–­ä¹¦ç±æ˜¯å¦æœ‰å°é¢ã€‚"""
    return bool((book.cover or "").strip())


def format_dt(value: datetime) -> str:
    """æ ¼å¼åŒ–æ—¶é—´ä¸ºä¸­å›½æ—¶åŒºå­—ç¬¦ä¸²ã€‚"""
    if not value:
        return "-"
    dt = value
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=timezone.utc)
    return dt.astimezone(CN_TZ).strftime("%Y-%m-%d %H:%M:%S")


def pick_book_to_keep(books: List[Book]) -> Book:
    """æŒ‰ç…§å°é¢ä¼˜å…ˆã€åˆ›å»ºæ—¶é—´æœ€æ—©çš„è§„åˆ™é€‰æ‹©ä¿ç•™ä¹¦ç±ã€‚"""
    candidates = [book for book in books if has_cover(book)]
    if not candidates:
        candidates = books

    def sort_key(book: Book):
        created = book.created_at or datetime.max.replace(tzinfo=None)
        return created, book.id

    return sorted(candidates, key=sort_key)[0]


def delete_book(session: Session, book: Book) -> Tuple[bool, List[str]]:
    """
    åˆ é™¤å•æœ¬ä¹¦ç±ï¼ŒåŒæ—¶æ¸…ç†Supabaseã€SQLiteå’Œå›¾ç‰‡ã€‚
    è¿”å› (æ˜¯å¦å…¨éƒ¨æˆåŠŸ, æ“ä½œæ—¥å¿—åˆ—è¡¨)ã€‚
    """
    book_id = book.id
    step_logs: List[str] = []
    errors: List[str] = []

    if supabase_client.enabled:
        try:
            supabase_client.delete_book(book_id)
            step_logs.append("å·²ä»Supabaseåˆ é™¤")
        except Exception as exc:  # noqa: BLE001
            errors.append(f"Supabaseåˆ é™¤å¤±è´¥: {exc}")
            step_logs.append(f"Supabaseåˆ é™¤å¤±è´¥: {exc}")
    else:
        step_logs.append("Supabaseæœªå¯ç”¨ï¼Œè·³è¿‡äº‘ç«¯è®°å½•åˆ é™¤")

    try:
        if oss_helper.enabled:
            oss_helper.delete_images(book_id)
            step_logs.append("å·²åˆ é™¤è¿œç¨‹å›¾ç‰‡")
        else:
            step_logs.append("OSSæœªå¯ç”¨ï¼Œè·³è¿‡è¿œç¨‹å›¾ç‰‡åˆ é™¤")
    except Exception as exc:  # noqa: BLE001
        errors.append(f"è¿œç¨‹å›¾ç‰‡åˆ é™¤å¤±è´¥: {exc}")
        step_logs.append(f"è¿œç¨‹å›¾ç‰‡åˆ é™¤å¤±è´¥: {exc}")

    try:
        oss_helper.delete_local_images(book_id, BACKEND_DIR)
        step_logs.append("å·²æ¸…ç†æœ¬åœ°å›¾ç‰‡ç›®å½•")
    except Exception as exc:  # noqa: BLE001
        errors.append(f"æœ¬åœ°å›¾ç‰‡åˆ é™¤å¤±è´¥: {exc}")
        step_logs.append(f"æœ¬åœ°å›¾ç‰‡åˆ é™¤å¤±è´¥: {exc}")

    try:
        session.query(Chapter).filter(Chapter.book_id == book_id).delete(synchronize_session=False)
        session.query(BookVocabulary).filter(BookVocabulary.book_id == book_id).delete(synchronize_session=False)
        session.delete(book)
        session.commit()
        step_logs.append("SQLiteè®°å½•åˆ é™¤å®Œæˆ")
    except Exception as exc:  # noqa: BLE001
        session.rollback()
        errors.append(f"SQLiteåˆ é™¤å¤±è´¥: {exc}")
        step_logs.append(f"SQLiteåˆ é™¤å¤±è´¥: {exc}")

    success = len(errors) == 0
    return success, step_logs


def collect_duplicates(books: List[Book]) -> Dict[str, List[Book]]:
    """æŒ‰ç…§å½’ä¸€åŒ–æ ‡é¢˜åˆ†ç»„ï¼Œè¿”å›é‡å¤é¡¹å­—å…¸ã€‚"""
    grouped: Dict[str, List[Book]] = defaultdict(list)
    for book in books:
        key = normalize_title(book.title)
        grouped[key].append(book)
    return {key: items for key, items in grouped.items() if len(items) > 1}


def write_report(
    entries: List[Dict],
    stats: Dict[str, int],
    dry_run: bool,
    log_path: str,
) -> None:
    """å°†å»é‡ç»“æœå†™å…¥Markdownæ—¥å¿—ã€‚"""
    os.makedirs(CLAUDE_DIR, exist_ok=True)
    now = datetime.now(CN_TZ)
    lines: List[str] = [
        "# ä¹¦ç±å»é‡æ—¥å¿—",
        f"- è®°å½•æ—¶é—´: {now.strftime('%Y-%m-%d %H:%M')} (UTC+8, Codex)",
        f"- æ‰§è¡Œæ¨¡å¼: {'Dry Runï¼ˆæœªå®é™…åˆ é™¤ï¼‰' if dry_run else 'å®é™…åˆ é™¤'}",
        f"- é‡å¤åˆ†ç»„æ€»æ•°: {stats['duplicate_groups']}",
        f"- å¾…åˆ é™¤ä¹¦ç±æ•°é‡: {stats['books_to_delete']}",
        f"- å®é™…åˆ é™¤æˆåŠŸ: {stats['deleted_success']}",
        f"- åˆ é™¤å¤±è´¥: {stats['deleted_failed']}",
        "",
    ]

    if not entries:
        lines.append("æœ¬æ¬¡æ‰«ææœªå‘ç°é‡å¤ä¹¦ç±ã€‚")
    else:
        for entry in entries:
            lines.append(f"## ç¬¬ {entry['index']} ç»„ Â· ã€Š{entry['display_title']}ã€‹")
            lines.append(f"- å½’ä¸€åŒ–æ ‡é¢˜: `{entry['normalized_title'] or '(ç©º)'}`")
            lines.append(f"- ç»„å†…ä¹¦ç±æ•°é‡: {entry['count']}")
            lines.append(f"- ä¿ç•™ä¹¦ç±ID: `{entry['kept_book_id']}`")
            lines.append("")
            lines.append("| ä¹¦ç±ID | æ ‡é¢˜ | å°é¢ | åˆ›å»ºæ—¶é—´ (UTC+8) | æ“ä½œ | ç»“æœ |")
            lines.append("| --- | --- | --- | --- | --- | --- |")
            for book in entry["books"]:
                lines.append(
                    f"| `{book['id']}` | {book['title'] or '-'} | {book['cover_status']} | "
                    f"{book['created_at']} | {book['action']} | {book['result']} |"
                )
            lines.append("")

    with open(log_path, "w", encoding="utf-8") as file:
        file.write("\n".join(lines))


def deduplicate_books(dry_run: bool) -> Tuple[bool, str]:
    """æ‰§è¡Œå»é‡é€»è¾‘ï¼Œè¿”å› (æ˜¯å¦å®Œå…¨æˆåŠŸ, æ—¥å¿—è·¯å¾„)ã€‚"""
    session: Session = SessionLocal()
    timestamp = datetime.now(CN_TZ).strftime("%Y%m%d-%H%M%S")
    log_path = os.path.join(CLAUDE_DIR, f"deduplication-log-{timestamp}.md")

    try:
        books = session.query(Book).all()
        logger.info("ğŸ“˜ å…±æŸ¥è¯¢åˆ° %s æœ¬ä¹¦ç±", len(books))

        duplicates = collect_duplicates(books)
        logger.info("ğŸ” å‘ç° %s ç»„å¯èƒ½çš„é‡å¤ä¹¦ç±", len(duplicates))

        if not duplicates:
            write_report([], {
                "duplicate_groups": 0,
                "books_to_delete": 0,
                "deleted_success": 0,
                "deleted_failed": 0,
            }, dry_run, log_path)
            logger.info("âœ… å»é‡å®Œæˆï¼Œæœªå‘ç°é‡å¤ä¹¦ç±ã€‚æ—¥å¿—: %s", log_path)
            return True, log_path

        entries = []
        stats = {
            "duplicate_groups": len(duplicates),
            "books_to_delete": 0,
            "deleted_success": 0,
            "deleted_failed": 0,
        }
        any_failure = False

        for index, key in enumerate(sorted(duplicates.keys()), start=1):
            group = duplicates[key]
            keep = pick_book_to_keep(group)
            to_delete = [book for book in group if book.id != keep.id]
            stats["books_to_delete"] += len(to_delete)

            logger.info(
                "â¡ï¸  ç¬¬ %s ç»„ã€Š%sã€‹ï¼šå…± %s æœ¬ï¼Œä¿ç•™ %sï¼Œè®¡åˆ’åˆ é™¤ %s æœ¬",
                index,
                keep.title or key or "æœªå‘½å",
                len(group),
                keep.id,
                len(to_delete),
            )

            book_rows = []
            ordered_group = sorted(group, key=lambda item: (item.id != keep.id, item.created_at or datetime.max))
            for book in ordered_group:
                action = "ä¿ç•™" if book.id == keep.id else ("åˆ é™¤" if not dry_run else "è®¡åˆ’åˆ é™¤")
                result_text = (
                    "ä¿ç•™"
                    if book.id == keep.id
                    else "Dry Run - æœªåˆ é™¤"
                    if dry_run
                    else "å¾…åˆ é™¤"
                )
                book_rows.append({
                    "id": book.id,
                    "title": book.title,
                    "cover_status": "æœ‰å°é¢" if has_cover(book) else "æ— å°é¢",
                    "created_at": format_dt(book.created_at) if book.created_at else "-",
                    "action": action,
                    "result": result_text,
                })

            if not dry_run:
                for book in to_delete:
                    success, steps = delete_book(session, book)
                    result_message = "åˆ é™¤æˆåŠŸ" if success else f"åˆ é™¤å¤±è´¥ï¼š{'ï¼›'.join(steps)}"
                    if success:
                        stats["deleted_success"] += 1
                    else:
                        stats["deleted_failed"] += 1
                        any_failure = True
                    logger.info("    â€¢ ä¹¦ç± %s â†’ %s", book.id, result_message)
                    for row in book_rows:
                        if row["id"] == book.id:
                            row["result"] = "ï¼›".join(steps) if steps else result_message
                            row["action"] = "åˆ é™¤"
                            if not success:
                                row["result"] = result_message
                            break
            else:
                logger.info("    â€¢ Dry Run æ¨¡å¼ï¼Œä»…è®°å½•å¾…åˆ é™¤ä¹¦ç±")

            entries.append({
                "index": index,
                "normalized_title": key,
                "display_title": keep.title or key or "æœªå‘½å",
                "kept_book_id": keep.id,
                "count": len(group),
                "books": book_rows,
            })

        write_report(entries, stats, dry_run, log_path)
        logger.info("ğŸ“ è¯¦ç»†æ—¥å¿—å·²å†™å…¥ %s", log_path)
        if dry_run:
            logger.info("ğŸ’¡ Dry Run æ¨¡å¼å®Œæˆï¼Œè¯·åœ¨ç¡®è®¤åç§»é™¤ --dry-run å‚æ•°æ‰§è¡Œå®é™…åˆ é™¤ã€‚")
            return True, log_path

        if stats["deleted_failed"] > 0:
            logger.warning("âš ï¸ æœ‰ %s æœ¬ä¹¦ç±åˆ é™¤å¤±è´¥ï¼Œè¯¦æƒ…è§æ—¥å¿—ã€‚", stats["deleted_failed"])
        else:
            logger.info("âœ… æ‰€æœ‰é‡å¤ä¹¦ç±åˆ é™¤æˆåŠŸã€‚")

        return not any_failure, log_path
    finally:
        session.close()


def main():
    """å‘½ä»¤è¡Œå…¥å£ã€‚"""
    parser = argparse.ArgumentParser(description="æŒ‰æ ‡é¢˜å»é‡ä¹¦ç±è®°å½•")
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ä»…æ‰“å°å°†è¢«åˆ é™¤çš„ä¹¦ç±ï¼Œä¸æ‰§è¡Œåˆ é™¤æ“ä½œ",
    )
    args = parser.parse_args()

    try:
        success, log_path = deduplicate_books(args.dry_run)
        if args.dry_run:
            logger.info("Dry Run å®Œæˆï¼Œæ—¥å¿—: %s", log_path)
        sys.exit(0 if success else 1)
    except Exception as exc:  # noqa: BLE001
        logger.exception("âŒ å»é‡è¿‡ç¨‹ä¸­å‡ºç°æœªæ•è·å¼‚å¸¸: %s", exc)
        sys.exit(1)


if __name__ == "__main__":
    main()
